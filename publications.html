<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="Exp.html">Experiences</a></div>
<div class="menu-item"><a href="">CV</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
</div>
<h2>Preprints</h2>
<h2>Conference Articles</h2>
<ul>
<li><p><b>Implicit Bias of Linear RNNs</b>. In <i>International Conference on Machine Learning (ICML),</i> 2021. <a href="https://proceedings.mlr.press/v139/emami21b">[paper]</a> <a href="https://icml.cc/virtual/2021/poster/10445">[video]</a><br />
<b>M. Emami</b>, M. Sahraee-Ardakan, P. Pandit, S. Rangan, AK. Fletcher <br />
Contemporary wisdom based on empirical studies suggests that standard recurrent neural networks (RNNs) do not perform well on tasks requiring long-term memory. However, RNNs&rsquo; poor ability to capture long-term dependencies has not been fully understood. This paper provides a rigorous explanation of this property in the special case of linear RNNs. Although this work is limited to linear RNNs, even these systems have traditionally been difficult to analyze due to their non-linear parameterization. Using recently-developed kernel regime analysis, our main result shows that as the number of hidden units goes to infinity, linear RNNs learned from random initializations are functionally equivalent to a certain weighted 1D-convolutional network. Importantly, the weightings in the equivalent model cause an implicit bias to elements with smaller time lags in the convolution, and hence shorter memory. The degree of this bias depends on the variance of the transition matrix at initialization and is related to the classic exploding and vanishing gradients problem. The theory is validated with both synthetic and real data experiments.</p>
</li>
</ul>
<ul>
<li><p><b>Generalization Error of Generalized Linear Models in High Dimensions</b>. In <i>International Conference on Machine Learning (ICML),</i> 2020. <a href="http://proceedings.mlr.press/v119/emami20a.html">[paper]</a> <a href="https://icml.cc/virtual/2020/poster/6565">[video]</a><br />
<b>M. Emami</b>, M. Sahraee-Ardakan, P. Pandit, S. Rangan, AK. Fletcher <br />
At the heart of machine learning lies the question of generalizability of learned rules over previously unseen data.  Increasing use of machine learning models in critical applications such as healthcare, autonomous driving, policy making, etc., calls for a detailed understanding of the underlying models for accountability and robustness.  Therefore, providing methods to quantify the generalization error of these models becomes crucial in assessing their fitness for use.  Bearing that in mind, this work considers Generalized Linear Models (GLMs) (i.e., single-layer neural networks) in the over-parameterized regime and provides a unified framework to exactly characterize the generalization error.  The results are more general than the prior analyses in this area and hold for a large class of generalization metrics, loss functions, and regularization schemes.  Also, in this framework we can capture a larger class of statistical models for  the  features  as  well  as  a  distributional  mismatch  between  training  and  test  datasets.</p>
</li>
</ul>
<ul>
<li><p><b>Input-Output Equivalence of Unitary and Contractive RNNs</b>. In <i>Advances in Neural Information Processing Systems (NeurIPS),</i> 2019. <a href="https://proceedings.neurips.cc/paper/2019/file/9c449771d0edc923c2713a7462cefa3b-Paper.pdf">[paper]</a> <a href="https://arxiv.org/abs/1910.13672">[arXiv]</a><br />
<b>M. Emami</b>, M. Sahraee-Ardakan, S. Rangan, AK. Fletcher <br />
This work aims to  rigorously  understand  a  constrained  version  of  Recurrent Neural Networks (RNNs). Training RNNs suffers from the so-called vanishing/exploding gradients problem.  The unitary RNN is a simple approach to mitigate this problem by imposing a unitary constraint on these networks.  A key question here is how restrictive this unitary constraint is on an RNN.  We theoretically show that for RNNs with ReLU activations, there is no loss in the expressiveness of the model from imposing the unitary constraint.</p>
</li>
</ul>
<ul>
<li><p><b>Low-Rank Nonlinear Decoding of Micro-ECoG from the Primary Auditory Cortex</b>. In <i>Conference  on  Cognitive  Computational Neuroscience (CCN),</i> 2018. <a href="https://ccneuro.org/2018/Papers/ViewPapers.asp?PaperNum=1276">[paper]</a> <a href="https://arxiv.org/abs/2005.05053">[arXiv]</a><br />
<b>M. Emami</b>, M. Sahraee-Ardakan, P. Pandit, AK. Fletcher, S. Rangan, M. Trumpis, B. Bent, C. Chiang, J. Viventi <br />
This work considers  using  deep  recurrent  networks  for  modeling  complex  neural  sensory  responses  in  the  brain.   A  key challenge is the relatively large number of parameters for these models relative to the available data. We developed a framework for decoding high-dimensional neural responses from the rat auditory cortex. We found that a neural network with a low-rank initial layer can provide significant model improvements compared totraditional decoding models.</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2022-06-08 17:16:24 PDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
